{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Yz0Kyy_ctH2S"
      },
      "source": [
        "#FedMD (IV): cooperative training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IL3sKOEYtH2V",
        "outputId": "3f37f5f0-40b8-4a05-e025-19c404b36370"
      },
      "outputs": [],
      "source": [
        "# Clone GitHub repository\n",
        "\n",
        "import os\n",
        "\n",
        "if not os.path.isdir('/content/aml_project'):\n",
        "  !git clone https://github.com/s295103/aml_project.git\n",
        "  %cd /content/aml_project\n",
        "else:\n",
        "  if os.getcwd() != \"/content/aml_project\":\n",
        "    %cd /content/aml_project/\n",
        "  !git pull origin\n",
        "\n",
        "import torch\n",
        "from utils import cifar_processing, load_model\n",
        "from fedmd import load_clients, Server, save_clients\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "ROOT = \"/content\"\n",
        "\n",
        "# Baselines folders\n",
        "BL_PATH = f\"{ROOT}/aml_project/results/fedmd/baselines\"\n",
        "UPPER_BL_PATH = f\"{ROOT}/aml_project/results/fedmd/upper_baselines\"\n",
        "IID_LOWER_BL_PATH = f\"{ROOT}/aml_project/results/fedmd/lower_baselines_iid\"\n",
        "NON_IID_LOWER_BL_PATH = f\"{ROOT}/aml_project/results/fedmd/lower_baselines_non_iid\"\n",
        "\n",
        "# CIFAR10 training set will be the public dataset used to compute the consensus\n",
        "PUB_TR_SET, _, _ = cifar_processing(False, 0, ROOT)\n",
        "\n",
        "# CIFAR100 test set will be used for testing the cooperative training\n",
        "PR_TR_SET, _, TEST_SET = cifar_processing(True, 0, ROOT) # Note: clients private data comes from CIFAR100 TRAINING set\n",
        "\n",
        "PR_NUM_CLASSES = len(PR_TR_SET.classes)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "urlsl_pQtH2X"
      },
      "source": [
        "##Cooperative training with IID private data distributions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vej4H0HNtH2Y",
        "outputId": "1faa4ba8-7709-42e4-f7f0-fe25b6895f7e"
      },
      "outputs": [],
      "source": [
        "# Load lower baselines clients\n",
        "clients = load_clients(IID_LOWER_BL_PATH)\n",
        "\n",
        "# Load partitions\n",
        "partitions = pickle.load(open(f\"{IID_LOWER_BL_PATH}/partitions.p\", \"rb\"))\n",
        "if partitions[\"dataset\"] != \"CIFAR100\" or partitions[\"alpha\"] != 1000:\n",
        "    raise Exception(\"Error: wrong partitions file\")\n",
        "else:\n",
        "    for name, client in clients.items():\n",
        "        client.private_data = torch.utils.data.Subset(PR_TR_SET, partitions[\"name\"])\n",
        "\n",
        "# Make results folder\n",
        "COOP_TRAINING_IID_PATH = f\"{ROOT}/coop_training_iid\"\n",
        "if not os.path.isdir(COOP_TRAINING_IID_PATH):\n",
        "    !mkdir $COOP_TRAINING_IID_PATH\n",
        "\n",
        "# Initialize server and start the cooperative training\n",
        "server_kwargs = dict(\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
        "    num_classes_pr_data = PR_NUM_CLASSES,\n",
        "    path = COOP_TRAINING_IID_PATH,\n",
        "    priv_train_epochs = 25,\n",
        "    lr = 1e-3, # Low because of gradient explosion\n",
        ")\n",
        "\n",
        "server = Server(clients, PUB_TR_SET, TEST_SET, **server_kwargs)\n",
        "\n",
        "# Declare kw arguments\n",
        "clients_kwargs = dict(\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
        "    lr = 1e-1,\n",
        "    #weight_decay = 1e-4,\n",
        "    #momentum = 0.9,\n",
        "    batch_size = 128,\n",
        "    path = COOP_TRAINING_IID_PATH,\n",
        "    num_workers = 8\n",
        ")\n",
        "\n",
        "# Initialize training for all the clients\n",
        "for name, client in clients.items():\n",
        "    params = client.model.parameters()\n",
        "    optimizer = torch.optim.Adam(params, lr = clients_kwargs[\"lr\"])#, momentum=clients_kwargs[\"momentum\"], weight_decay=clients_kwargs[\"weight_decay\"])\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, server_kwargs[\"priv_train_epochs\"], 0.1*clients_kwargs[\"lr\"])\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    client.init_coop_training(optimizer, criterion, **clients_kwargs)\n",
        "\n",
        "stats = server.coop_training()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vhDU9unVtH2Z"
      },
      "outputs": [],
      "source": [
        "# Load best model onto clients and serialize them\n",
        "for name, client in clients.items():\n",
        "    client_data = load_model(f\"{COOP_TRAINING_IID_PATH}/{name}_best_model.pth\")\n",
        "    client.model.load_state_dict(client_data[\"weights\"])\n",
        "save_clients(clients, COOP_TRAINING_IID_PATH)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "e42pBXtstH2Z"
      },
      "source": [
        "###Plot results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "91VByVtRtH2a"
      },
      "outputs": [],
      "source": [
        "COOP_TRAINING_IID_PATH = f\"{ROOT}/aml_project/results/fedmd/coop_training_iid\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "HBZKQQD1tH2a",
        "outputId": "cd8295be-b12d-4ab9-d9fd-64882e8ac418"
      },
      "outputs": [],
      "source": [
        "# Unpickle stats\n",
        "stats = pickle.load(open(f\"{COOP_TRAINING_IID_PATH}/stats.p\", \"rb\"))\n",
        "acc_per_round = stats[\"acc\"]\n",
        "num_rounds = max([len(r) for r in acc_per_round])\n",
        "\n",
        "# Load upper and lower baselines data\n",
        "client_names = list(clients.keys())\n",
        "up_bl_acc = []\n",
        "low_bl_acc = []\n",
        "for name in client_names:\n",
        "    up_bl_acc.append(load_model(f\"{UPPER_BL_PATH}/{name}_best_model.pth\")[\"accuracy\"])\n",
        "    low_bl_acc.append(load_model(f\"{IID_LOWER_BL_PATH}/{name}_best_model.pth\")[\"accuracy\"])\n",
        "\n",
        "\n",
        "# Plot baselines accuracies and accuracy across rounds\n",
        "plt.figure()\n",
        "x = [_ for _ in range(num_rounds)]\n",
        "low_bl_x = [_ for _ in range(int(num_rounds/3))]\n",
        "up_bl_x = [_ for _ in range(int(2*num_rounds/3))]\n",
        "for i in range(len(client_names)):\n",
        "    low_bl_y = [100*low_bl_acc[i] for _ in range(len(low_bl_x))]\n",
        "    plt.plot(low_bl_x, low_bl_y, \"--\", label=client_names[i])\n",
        "\n",
        "    up_bl_y = [100*up_bl_acc[i] for _ in range(len(up_bl_x))]\n",
        "    plt.plot(low_bl_x, low_bl_y, \"-.\", label=client_names[i])\n",
        "\n",
        "    y = [100*a for a in acc_per_round[i]]\n",
        "    plt.plot(x, y, \"-o\", label=client_names[i])\n",
        "\n",
        "plt.xlabel(\"Round\")\n",
        "plt.ylabel(\"Test Accuracy [%]\")\n",
        "plt.title(\"Accuracy per Round: IID\")\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.savefig(f\"{COOP_TRAINING_IID_PATH}/results\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "oGKuuDZWtH2b"
      },
      "source": [
        "##Cooperative training with non-IID private data distributions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q6CIaEsktH2b"
      },
      "outputs": [],
      "source": [
        "# Load lower baselines clients\n",
        "clients = load_clients(NON_IID_LOWER_BL_PATH)\n",
        "\n",
        "# Load partitions\n",
        "partitions = pickle.load(open(f\"{NON_IID_LOWER_BL_PATH}/partitions.p\", \"rb\"))\n",
        "if partitions[\"dataset\"] != \"CIFAR100\" or partitions[\"alpha\"] != 0:\n",
        "    raise Exception(\"Error: wrong partitions file\")\n",
        "else:\n",
        "    for name, client in clients.items():\n",
        "        client.private_data = torch.utils.data.Subset(PR_TR_SET, partitions[\"name\"])\n",
        "\n",
        "# Make results folder\n",
        "COOP_TRAINING_NON_IID_PATH = f\"{ROOT}/coop_training_iid\"\n",
        "if not os.path.isdir(COOP_TRAINING_NON_IID_PATH):\n",
        "    !mkdir $COOP_TRAINING_NON_IID_PATH\n",
        "\n",
        "# Initialize server and start the cooperative training\n",
        "server_kwargs = dict(\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
        "    num_classes_pr_data = PR_NUM_CLASSES,\n",
        "    path = COOP_TRAINING_NON_IID_PATH,\n",
        "    priv_train_epochs = 25,\n",
        "    lr = 1e-3, # Low because of gradient explosion\n",
        ")\n",
        "\n",
        "server = Server(clients, PUB_TR_SET, TEST_SET, **server_kwargs)\n",
        "\n",
        "# Declare kw arguments\n",
        "clients_kwargs = dict(\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
        "    lr = 1e-1,\n",
        "    #weight_decay = 1e-4,\n",
        "    #momentum = 0.9,\n",
        "    batch_size = 128,\n",
        "    path = COOP_TRAINING_NON_IID_PATH,\n",
        "    num_workers = 8\n",
        ")\n",
        "\n",
        "# Initialize training for all the clients\n",
        "for name, client in clients.items():\n",
        "    params = client.model.parameters()\n",
        "    optimizer = torch.optim.Adam(params, lr = clients_kwargs[\"lr\"])#, momentum=clients_kwargs[\"momentum\"], weight_decay=clients_kwargs[\"weight_decay\"])\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, server_kwargs[\"priv_train_epochs\"], 0.1*clients_kwargs[\"lr\"])\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    client.init_coop_training(optimizer, criterion, **clients_kwargs)\n",
        "\n",
        "stats = server.coop_training()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GBqN69zxtH2c"
      },
      "outputs": [],
      "source": [
        "# Load best model onto clients and serialize them\n",
        "for name, client in clients.items():\n",
        "    client_data = load_model(f\"{COOP_TRAINING_NON_IID_PATH}/{name}_best_model.pth\")\n",
        "    client.model.load_state_dict(client_data[\"weights\"])\n",
        "save_clients(clients, COOP_TRAINING_NON_IID_PATH)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "svtiOJfAtH2c"
      },
      "source": [
        "###Plot results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S7CXiIC2tH2d"
      },
      "outputs": [],
      "source": [
        "COOP_TRAINING_NON_IID_PATH = f\"{ROOT}/aml_project/results/fedmd/coop_training_non_iid\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K83cfwQgtH2d"
      },
      "outputs": [],
      "source": [
        "# Unpickle stats\n",
        "stats = pickle.load(open(f\"{COOP_TRAINING_NON_IID_PATH}/stats.p\", \"rb\"))\n",
        "acc_per_round = stats[\"acc\"]\n",
        "num_rounds = max([len(r) for r in acc_per_round])\n",
        "\n",
        "# Load upper and lower baselines data\n",
        "client_names = list(clients.keys())\n",
        "up_bl_acc = []\n",
        "low_bl_acc = []\n",
        "for name in client_names:\n",
        "    up_bl_acc.append(load_model(f\"{UPPER_BL_PATH}/{name}_best_model.pth\")[\"accuracy\"])\n",
        "    low_bl_acc.append(load_model(f\"{NON_IID_LOWER_BL_PATH}/{name}_best_model.pth\")[\"accuracy\"])\n",
        "\n",
        "\n",
        "# Plot baselines accuracies and accuracy across rounds\n",
        "plt.figure()\n",
        "x = [_ for _ in range(num_rounds)]\n",
        "low_bl_x = [_ for _ in range(int(num_rounds/3))]\n",
        "up_bl_x = [_ for _ in range(int(2*num_rounds/3))]\n",
        "for i in range(len(client_names)):\n",
        "    low_bl_y = [100*low_bl_acc[i] for _ in range(len(low_bl_x))]\n",
        "    plt.plot(low_bl_x, low_bl_y, \"--\", label=client_names[i])\n",
        "\n",
        "    up_bl_y = [100*up_bl_acc[i] for _ in range(len(up_bl_x))]\n",
        "    plt.plot(low_bl_x, low_bl_y, \"-.\", label=client_names[i])\n",
        "\n",
        "    y = [100*a for a in acc_per_round[i]]\n",
        "    plt.plot(x, y, \"-o\", label=client_names[i])\n",
        "\n",
        "plt.xlabel(\"Round\")\n",
        "plt.ylabel(\"Test Accuracy [%]\")\n",
        "plt.title(\"Accuracy per Round: Non-IID\")\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.savefig(f\"{COOP_TRAINING_NON_IID_PATH}/results\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
