{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "RPXiXR9OhwvB"
      },
      "source": [
        "#Implementing InstaHide\n",
        "In this notebook we implement the algorithm from the paper [InstaHide: Instance-hiding Schemes for Private Distributed Learning](https://arxiv.org/abs/2010.02772)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "gaKXzO9yhwvG"
      },
      "source": [
        "##Clone GitHub repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4lo51kC3hwvH"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "if not os.path.isdir('aml_project'):\n",
        "  !git clone https://github.com/s295103/aml_project.git\n",
        "else:\n",
        "  %cd aml_project/\n",
        "  !git pull origin\n",
        "  %cd .."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "O1V7151ahwvI"
      },
      "source": [
        "##Import libraries and define constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kEpLsGxchwvI"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import CIFAR100, Caltech101\n",
        "from aml_project.utils import cifar_processing, load_model\n",
        "from aml_project.architectures import ResNet, BasicBlock\n",
        "from aml_project.instahide import InstaHide\n",
        "import matplotlib.pyplot as plt\n",
        "import csv\n",
        "import pickle\n",
        "\n",
        "ROOT = os.getcwd()\n",
        "BATCH_SIZE = 128\n",
        "NUM_CLASSES = 100\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "CH_MEAN = (0.485, 0.456, 0.406) # ImageNet's Mean\n",
        "CH_STDDEV = (0.229, 0.224, 0.225) # ImageNet's Std Dev"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Vm_HSGdIhwvJ"
      },
      "source": [
        "##Visualize InstaHide encryption"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C2LBVgIAhwvK"
      },
      "outputs": [],
      "source": [
        "# Get dataset\n",
        "data = CIFAR100(ROOT, True, download=True)\n",
        "n = len(data)\n",
        "\n",
        "# Get a batch of images\n",
        "sample_idxs = torch.randint(0, n, (BATCH_SIZE,))\n",
        "imgs = []\n",
        "labs = []\n",
        "for i in sample_idxs:\n",
        "    img, lab = data[i]\n",
        "    imgs.append(img)\n",
        "    labs.append(lab)\n",
        "\n",
        "# Load label ids to names mapping\n",
        "with open(ROOT + \"/cifar-100-python/meta\", \"rb\") as f:\n",
        "    label_names = pickle.load(f)\n",
        "\n",
        "# Transform\n",
        "tr_imgs = torch.empty(BATCH_SIZE, 3, 32, 32)\n",
        "transform_imgs = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(CH_MEAN, CH_STDDEV)\n",
        "])\n",
        "# Apply transform\n",
        "for i, im in enumerate(imgs):\n",
        "    tr_imgs[i] = transform_imgs(im)\n",
        "\n",
        "# Compute inverse normalization transform\n",
        "# y = (x - mean) / stddev =>  x = 1/stddev * (y - (-mean/stddev))\n",
        "inv_ch_mean = [-m/s for m, s in zip(CH_MEAN, CH_STDDEV)]\n",
        "inv_ch_stddev = [1/s for s in CH_STDDEV]\n",
        "transform_enc_imgs = transforms.Compose([\n",
        "    transforms.Normalize(inv_ch_mean, inv_ch_stddev),\n",
        "    transforms.ToPILImage(),\n",
        "])\n",
        "\n",
        "# Initialize multiple instances of InstaHide with different k\n",
        "kmin=1\n",
        "kmax=4\n",
        "instahide = [InstaHide(k = k, device=DEVICE ) for k in range(kmin, kmax+1)]\n",
        "\n",
        "# Encode images for different k\n",
        "enc_imgs = []\n",
        "for ih in instahide:\n",
        "    enc_imgs.append(ih.encode(tr_imgs, NUM_CLASSES, torch.Tensor(labs))[0])\n",
        "\n",
        "# Transpose so that each element contains all encodings of the same image\n",
        "enc_imgs = [_ for _ in zip(*enc_imgs)]\n",
        "\n",
        "# Sample images from batch\n",
        "num_samples = 5\n",
        "sampled_idxs = torch.randint(0, BATCH_SIZE, (num_samples,))\n",
        "imgs_to_plot = []\n",
        "labs_to_plot = []\n",
        "enc_imgs_to_plot = []\n",
        "for i in sampled_idxs:\n",
        "    imgs_to_plot.append(imgs[i])\n",
        "    labs_to_plot.append(labs[i])\n",
        "    enc_imgs_to_plot.append(enc_imgs[i])\n",
        "\n",
        "# Un-transform encrypted images\n",
        "for i, imgs in enumerate(enc_imgs_to_plot):\n",
        "    enc_imgs_to_plot[i] = [transform_enc_imgs(im) for im in imgs]\n",
        "\n",
        "# Plot original and encrypted images\n",
        "fig, axs = plt.subplots(num_samples, kmax+1)\n",
        "for i in range(num_samples):\n",
        "    for k in range(kmax+1):\n",
        "        # Set column title\n",
        "        if k == 0:\n",
        "            axs[0, k].set_title(\"Original Image\")\n",
        "        else:\n",
        "            axs[0, k].set_title(\"k = \" + str(k))\n",
        "\n",
        "        # Set tick labels and params\n",
        "        axs[i, k].set_xticklabels([])\n",
        "        axs[i, k].set_yticklabels([])\n",
        "        axs[i, k].tick_params(labelcolor='w', top=False, bottom=False, left=False, right=False)\n",
        "\n",
        "        # Plot images\n",
        "        if k == 0:\n",
        "            axs[i, k].set_ylabel(label_names[\"fine_label_names\"][labs_to_plot[i]])\n",
        "            axs[i, k].imshow(imgs_to_plot[i])\n",
        "        else:\n",
        "            axs[i, k].imshow(enc_imgs_to_plot[i][k-1])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(ROOT + '/original_vs_instahide_encryption')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "6MWtZSdMhwvL"
      },
      "source": [
        "##Define the training routine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vV8PFQdphwvM"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "VAL_RATIO = 0.2\n",
        "GROUPS = 2\n",
        "NORM_LAYER = \"gn\"\n",
        "LAYERS = [3, 3, 3]\n",
        "\n",
        "# Make ResNet20\n",
        "NET = ResNet(BasicBlock, LAYERS, num_classes=NUM_CLASSES, norm_layer=NORM_LAYER, groups=GROUPS)\n",
        "\n",
        "# Training, validation and test set\n",
        "TRAIN_SET, VAL_SET, TEST_SET = cifar_processing(\n",
        "    cifar100=True,\n",
        "    val_ratio=VAL_RATIO,\n",
        "    root=ROOT\n",
        "    )\n",
        "\n",
        "# Training routine\n",
        "def instahide_train_on_cifar(\n",
        "    k:int,\n",
        "    num_epochs:int,\n",
        "    lr:float,\n",
        "    momentum:float,\n",
        "    weight_decay:float,\n",
        "    file_path: str,\n",
        "    public_dataset:Dataset=None,\n",
        "    checkpoint_file:str=None,\n",
        "    num_workers:int = 4\n",
        ") -> tuple[float, float]:\n",
        "\n",
        "    instahide = InstaHide(\n",
        "                      k = k,\n",
        "                      device=DEVICE,\n",
        "                      c = 0.65, # Default value used in the paper\n",
        "                      num_pred = 5,\n",
        "                      num_workers = num_workers\n",
        "                      )\n",
        "\n",
        "    val_acc = instahide.training(\n",
        "                            net = NET,\n",
        "                            training_set = TRAIN_SET,\n",
        "                            validation_set = VAL_SET,\n",
        "                            num_classes = NUM_CLASSES,\n",
        "                            num_epochs = num_epochs,\n",
        "                            batch_size = BATCH_SIZE,\n",
        "                            lr = lr,\n",
        "                            momentum = momentum,\n",
        "                            weight_decay = weight_decay,\n",
        "                            path= file_path,\n",
        "                            public_dataset = public_dataset,\n",
        "                            resume_file = checkpoint_file,\n",
        "                            val_freq=10,\n",
        "                            )\n",
        "\n",
        "    test_acc = instahide.inference(\n",
        "                              net = NET,\n",
        "                              test_set = TEST_SET,\n",
        "                              num_classes = NUM_CLASSES,\n",
        "                              batch_size = BATCH_SIZE,\n",
        "                              model_path = file_path + \"/best_model.pth\",\n",
        "                              encoding_data = TRAIN_SET\n",
        "                              )\n",
        "\n",
        "    return val_acc, test_acc"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "HDPzDUFNhwvN"
      },
      "source": [
        "##Train with Inside InstaHide"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OCO2f7VShwvO"
      },
      "outputs": [],
      "source": [
        "#Train for k values ranging from 1 to 4\n",
        "\n",
        "if not os.path.isdir('inside'):\n",
        "  !mkdir inside\n",
        "\n",
        "k = [1, 2, 3, 4]\n",
        "lr = [0.1, 0.1, 0.1, 0.1]\n",
        "weight_decay = [1e-4, 1e-4, 1e-4, 1e-4]\n",
        "momentum = [0.9, 0.9, 0.9, 0.9]\n",
        "num_epochs = [250, 250, 250, 250]\n",
        "num_workers = 8\n",
        "\n",
        "inside_acc = {}\n",
        "for i in range(3, 4):\n",
        "#for i in range(4):\n",
        "    dirname=os.getcwd() + \"/inside/k_\" + str(k[i])\n",
        "    !mkdir $dirname\n",
        "    _, test_acc = instahide_train_on_cifar(\n",
        "                                      k = k[i],\n",
        "                                      num_epochs = num_epochs[i],\n",
        "                                      lr = lr[i],\n",
        "                                      momentum = momentum[i],\n",
        "                                      weight_decay = weight_decay[i],\n",
        "                                      file_path = dirname,\n",
        "                                      checkpoint_file=dirname + \"/checkpoint.pth\",\n",
        "                                      num_workers = num_workers\n",
        "                                      )\n",
        "    inside_acc.update({k[i]:test_acc})\n",
        "    with open(\"test_acc.csv\", \"a\") as file:\n",
        "      writer = csv.writer(file)\n",
        "      writer.writerow([k[i], test_acc])\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "JA_Kd03RhwvP"
      },
      "source": [
        "##Plot k vs accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AtcOaswHhwvQ"
      },
      "outputs": [],
      "source": [
        "# Load accuracy data\n",
        "try:\n",
        "  inside_acc # Check if it exists\n",
        "  if inside_acc is None or not bool(inside_acc):\n",
        "    Exception()\n",
        "except:\n",
        "  with open(\"inside/test_acc.csv\", \"r\") as file:\n",
        "    reader = csv.reader(file)\n",
        "    inside_acc = {}\n",
        "    for k, acc in reader:\n",
        "        inside_acc.update({int(k):float(acc)})\n",
        "\n",
        "# Load vanilla ResNet20 test accuracy\n",
        "model = load_model(ROOT + \"/aml_project/results/models/resnet20/resnet20_gn/best_model.pth\")\n",
        "five_perc = 0.95*100*model[\"accuracy\"]\n",
        "\n",
        "\n",
        "plt.title(\"Inside InstaHide\")\n",
        "plt.ylabel(\"Test Accuracy [%]\")\n",
        "plt.xlabel(\"k\")\n",
        "kappas = list(inside_acc.keys())\n",
        "top_acc = [100*model[\"accuracy\"] for _ in range(len(inside_acc))]\n",
        "accs = [100*a for a in list(inside_acc.values())]\n",
        "plt.xlim(min(kappas), max(kappas))\n",
        "plt.xticks(kappas)\n",
        "plt.grid(True)\n",
        "plt.plot(kappas, top_acc, \"--g\", label=\"Vanilla\")\n",
        "plt.plot(kappas, accs, \"-sb\", label=\"InstaHide\")\n",
        "plt.fill_between(kappas, top_acc, five_perc, color=\"b\", alpha=0.2, label=\"5% range\")\n",
        "plt.legend()\n",
        "\n",
        "plt.savefig(ROOT + \"/inside_k_vs_accuracy\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "FLueWqbuw4jG"
      },
      "source": [
        "##Train with Cross InstaHide"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "29YrGvf9hwvP"
      },
      "outputs": [],
      "source": [
        "# Prepare public dataset\n",
        "public_transforms = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(32),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Lambda(lambda x:x.repeat(3, 1, 1) if x.size() != (3, 32, 32) else x),\n",
        "    transforms.Normalize(CH_MEAN, CH_STDDEV)\n",
        "    ])\n",
        "\n",
        "# We use Caltech101 as public dataset, since ImageNet it's too large to download\n",
        "public_data = Caltech101(ROOT, transform=public_transforms, download=True)\n",
        "\n",
        "# Make destination folder\n",
        "if not os.path.isdir('cross'):\n",
        "  !mkdir cross\n",
        "\n",
        "dirname = os.getcwd() + \"/cross\"\n",
        "k = 2\n",
        "num_workers = 4 # Reduce it because we need two dataloaders\n",
        "\n",
        "_, test_acc = instahide_train_on_cifar(\n",
        "                                  k = k,\n",
        "                                  lr = 0.1,\n",
        "                                  num_epochs = 250,\n",
        "                                  weight_decay = 1e-4,\n",
        "                                  momentum = 0.9,\n",
        "                                  file_path = dirname,\n",
        "                                  public_dataset = public_data,\n",
        "                                  checkpoint_file=dirname + \"/checkpoint.pth\",\n",
        "                                  num_workers = num_workers\n",
        "                                  )\n",
        "print(\"Cross InstaHide\")\n",
        "print(f\"\\tTest accuracy for k = {k} : {100*test_acc:.1f}%\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuClass": "premium",
      "gpuType": "T4",
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
