{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yz0Kyy_ctH2S"
      },
      "source": [
        "#FedMD (IV): cooperative training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "IL3sKOEYtH2V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b20b03b8-048c-4b05-a5ee-1eacd9a12284"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/aml_project\n",
            "remote: Enumerating objects: 5, done.\u001b[K\n",
            "remote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1/1), done.\u001b[K\n",
            "remote: Total 3 (delta 2), reused 3 (delta 2), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (3/3), 475 bytes | 475.00 KiB/s, done.\n",
            "From https://github.com/s295103/aml_project\n",
            "   5b1e54d..8073b20  main       -> origin/main\n",
            "Updating 5b1e54d..8073b20\n",
            "Fast-forward\n",
            " fedmd.py | 19 \u001b[32m++++++++++++++\u001b[m\u001b[31m-----\u001b[m\n",
            " 1 file changed, 14 insertions(+), 5 deletions(-)\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "# Clone GitHub repository\n",
        "\n",
        "import os\n",
        "\n",
        "if not os.path.isdir('/content/aml_project'):\n",
        "  !git clone https://github.com/s295103/aml_project.git\n",
        "  %cd /content/aml_project\n",
        "else:\n",
        "  if os.getcwd() != \"/content/aml_project\":\n",
        "    %cd /content/aml_project/\n",
        "  !git pull origin\n",
        "\n",
        "import torch\n",
        "from utils import cifar_processing, load_model\n",
        "from fedmd import load_clients, Server, save_clients\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "ROOT = \"/content\"\n",
        "\n",
        "# Baselines folders\n",
        "BL_PATH = f\"{ROOT}/aml_project/results/fedmd/baselines\"\n",
        "UPPER_BL_PATH = f\"{ROOT}/aml_project/results/fedmd/upper_baselines\"\n",
        "IID_LOWER_BL_PATH = f\"{ROOT}/aml_project/results/fedmd/lower_baselines_iid\"\n",
        "NON_IID_LOWER_BL_PATH = f\"{ROOT}/aml_project/results/fedmd/lower_baselines_non_iid\"\n",
        "\n",
        "# CIFAR10 training set will be the public dataset used to compute the consensus\n",
        "PUB_TR_SET, _, _ = cifar_processing(False, 0, ROOT)\n",
        "\n",
        "# CIFAR100 test set will be used for testing the cooperative training\n",
        "PR_TR_SET, _, TEST_SET = cifar_processing(True, 0, ROOT) # Note: clients private data comes from CIFAR100 TRAINING set\n",
        "\n",
        "PR_NUM_CLASSES = len(PR_TR_SET.classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "urlsl_pQtH2X"
      },
      "source": [
        "##Cooperative training with IID private data distributions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vej4H0HNtH2Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffb6cf56-74d7-4ff1-a862-d2c18831d33a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 0\n",
            "resnet20gn private training\n",
            "Epoch 0, avg_loss = 219.64768757397616\n",
            "Epoch 1, avg_loss = 29.98143703122682\n",
            "Epoch 2, avg_loss = 8.971697372726247\n",
            "Epoch 3, avg_loss = 4.931163588656655\n",
            "Epoch 4, avg_loss = 4.517375891721701\n",
            "Epoch 5, avg_loss = 4.467809302897393\n",
            "Epoch 6, avg_loss = 4.4349948605404625\n",
            "Epoch 7, avg_loss = 4.437948311431499\n",
            "Epoch 8, avg_loss = 4.400650440892087\n",
            "Epoch 9, avg_loss = 4.392600475987302\n",
            "resnet20gn accuracy = 1.0 %\n",
            "shufflenetbig private training\n",
            "Epoch 0, avg_loss = 607.436115651191\n",
            "Epoch 1, avg_loss = 197.7550075869017\n",
            "Epoch 2, avg_loss = 65.80486978458453\n",
            "Epoch 3, avg_loss = 8.909768563282642\n",
            "Epoch 4, avg_loss = 4.657307878325257\n",
            "Epoch 5, avg_loss = 4.618750867964346\n",
            "Epoch 6, avg_loss = 4.607977885234205\n",
            "Epoch 7, avg_loss = 4.58311000654969\n",
            "Epoch 8, avg_loss = 4.563133722619165\n",
            "Epoch 9, avg_loss = 4.557413910008684\n",
            "shufflenetbig accuracy = 1.0 %\n",
            "shufflenetsmall private training\n",
            "Epoch 0, avg_loss = 227.9778345325325\n",
            "Epoch 1, avg_loss = 55.306109875063356\n",
            "Epoch 2, avg_loss = 7.101237876505792\n"
          ]
        }
      ],
      "source": [
        "# Load lower baselines clients\n",
        "clients = load_clients(IID_LOWER_BL_PATH)\n",
        "\n",
        "# Load partitions\n",
        "partitions = pickle.load(open(f\"{IID_LOWER_BL_PATH}/partitions.p\", \"rb\"))\n",
        "if partitions[\"dataset\"] != \"CIFAR100\" or partitions[\"alpha\"] != 1000:\n",
        "    raise Exception(\"Error: wrong partitions file\")\n",
        "else:\n",
        "    for name, client in clients.items():\n",
        "        client.private_data = torch.utils.data.Subset(PR_TR_SET, partitions[\"name\"])\n",
        "\n",
        "# Make results folder\n",
        "COOP_TRAINING_IID_PATH = f\"{ROOT}/coop_training_iid\"\n",
        "if not os.path.isdir(COOP_TRAINING_IID_PATH):\n",
        "    !mkdir $COOP_TRAINING_IID_PATH\n",
        "\n",
        "# Initialize server and start the cooperative training\n",
        "server_kwargs = dict(\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
        "    num_classes_pr_data = PR_NUM_CLASSES,\n",
        "    path = COOP_TRAINING_IID_PATH,\n",
        "    priv_train_epochs = 10,\n",
        "    pub_train_epochs = 1,\n",
        "    lr = 1e-3,\n",
        ")\n",
        "\n",
        "server = Server(clients, PUB_TR_SET, TEST_SET, **server_kwargs)\n",
        "\n",
        "# Declare kw arguments\n",
        "clients_kwargs = dict(\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
        "    lr = 1e-1,\n",
        "    #weight_decay = 1e-4,\n",
        "    #momentum = 0.9,\n",
        "    batch_size = 128,\n",
        "    path = COOP_TRAINING_IID_PATH,\n",
        "    num_workers = 8\n",
        ")\n",
        "\n",
        "# Initialize training for all the clients\n",
        "for name, client in clients.items():\n",
        "    params = client.model.parameters()\n",
        "    optimizer = torch.optim.Adam(params, lr = clients_kwargs[\"lr\"])#, momentum=clients_kwargs[\"momentum\"], weight_decay=clients_kwargs[\"weight_decay\"])\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, server_kwargs[\"priv_train_epochs\"], 0.1*clients_kwargs[\"lr\"])\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    client.init_coop_training(optimizer, criterion, scheduler, **clients_kwargs)\n",
        "\n",
        "stats = server.coop_training()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vhDU9unVtH2Z"
      },
      "outputs": [],
      "source": [
        "# Load best model onto clients and serialize them\n",
        "for name, client in clients.items():\n",
        "    client_data = load_model(f\"{COOP_TRAINING_IID_PATH}/{name}_best_model.pth\")\n",
        "    client.model.load_state_dict(client_data[\"weights\"])\n",
        "save_clients(clients, COOP_TRAINING_IID_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e42pBXtstH2Z"
      },
      "source": [
        "###Plot results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "91VByVtRtH2a"
      },
      "outputs": [],
      "source": [
        "COOP_TRAINING_IID_PATH = f\"{ROOT}/aml_project/results/fedmd/coop_training_iid\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HBZKQQD1tH2a"
      },
      "outputs": [],
      "source": [
        "# Unpickle stats\n",
        "stats = pickle.load(open(f\"{COOP_TRAINING_IID_PATH}/stats.p\", \"rb\"))\n",
        "acc_per_round = stats[\"acc\"]\n",
        "num_rounds = max([len(r) for r in acc_per_round])\n",
        "\n",
        "# Load upper and lower baselines data\n",
        "client_names = list(clients.keys())\n",
        "up_bl_acc = []\n",
        "low_bl_acc = []\n",
        "for name in client_names:\n",
        "    up_bl_acc.append(load_model(f\"{UPPER_BL_PATH}/{name}_best_model.pth\")[\"accuracy\"])\n",
        "    low_bl_acc.append(load_model(f\"{IID_LOWER_BL_PATH}/{name}_best_model.pth\")[\"accuracy\"])\n",
        "\n",
        "\n",
        "# Plot baselines accuracies and accuracy across rounds\n",
        "plt.figure()\n",
        "x = [_ for _ in range(num_rounds)]\n",
        "low_bl_x = [_ for _ in range(int(num_rounds/3))]\n",
        "up_bl_x = [_ for _ in range(int(2*num_rounds/3))]\n",
        "for i in range(len(client_names)):\n",
        "    low_bl_y = [100*low_bl_acc[i] for _ in range(len(low_bl_x))]\n",
        "    plt.plot(low_bl_x, low_bl_y, \"--\", label=client_names[i])\n",
        "\n",
        "    up_bl_y = [100*up_bl_acc[i] for _ in range(len(up_bl_x))]\n",
        "    plt.plot(low_bl_x, low_bl_y, \"-.\", label=client_names[i])\n",
        "\n",
        "    y = [100*a for a in acc_per_round[i]]\n",
        "    plt.plot(x, y, \"-o\", label=client_names[i])\n",
        "\n",
        "plt.xlabel(\"Round\")\n",
        "plt.ylabel(\"Test Accuracy [%]\")\n",
        "plt.title(\"Accuracy per Round: IID\")\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.savefig(f\"{COOP_TRAINING_IID_PATH}/results\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGKuuDZWtH2b"
      },
      "source": [
        "##Cooperative training with non-IID private data distributions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q6CIaEsktH2b"
      },
      "outputs": [],
      "source": [
        "# Load lower baselines clients\n",
        "clients = load_clients(NON_IID_LOWER_BL_PATH)\n",
        "\n",
        "# Load partitions\n",
        "partitions = pickle.load(open(f\"{NON_IID_LOWER_BL_PATH}/partitions.p\", \"rb\"))\n",
        "if partitions[\"dataset\"] != \"CIFAR100\" or partitions[\"alpha\"] != 0:\n",
        "    raise Exception(\"Error: wrong partitions file\")\n",
        "else:\n",
        "    for name, client in clients.items():\n",
        "        client.private_data = torch.utils.data.Subset(PR_TR_SET, partitions[\"name\"])\n",
        "\n",
        "# Make results folder\n",
        "COOP_TRAINING_NON_IID_PATH = f\"{ROOT}/coop_training_non_iid\"\n",
        "if not os.path.isdir(COOP_TRAINING_NON_IID_PATH):\n",
        "    !mkdir $COOP_TRAINING_NON_IID_PATH\n",
        "\n",
        "# Initialize server and start the cooperative training\n",
        "server_kwargs = dict(\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
        "    num_classes_pr_data = PR_NUM_CLASSES,\n",
        "    path = COOP_TRAINING_NON_IID_PATH,\n",
        "    priv_train_epochs = 10,\n",
        "    pub_train_epochs = 1,\n",
        "    lr = 1e-3,\n",
        ")\n",
        "\n",
        "server = Server(clients, PUB_TR_SET, TEST_SET, **server_kwargs)\n",
        "\n",
        "# Declare kw arguments\n",
        "clients_kwargs = dict(\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
        "    lr = 1e-1,\n",
        "    #weight_decay = 1e-4,\n",
        "    #momentum = 0.9,\n",
        "    batch_size = 128,\n",
        "    path = COOP_TRAINING_NON_IID_PATH,\n",
        "    num_workers = 8\n",
        ")\n",
        "\n",
        "# Initialize training for all the clients\n",
        "for name, client in clients.items():\n",
        "    params = client.model.parameters()\n",
        "    optimizer = torch.optim.Adam(params, lr = clients_kwargs[\"lr\"])#, momentum=clients_kwargs[\"momentum\"], weight_decay=clients_kwargs[\"weight_decay\"])\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, server_kwargs[\"priv_train_epochs\"], 0.1*clients_kwargs[\"lr\"])\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    client.init_coop_training(optimizer, criterion, scheduler, **clients_kwargs)\n",
        "\n",
        "stats = server.coop_training()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GBqN69zxtH2c"
      },
      "outputs": [],
      "source": [
        "# Load best model onto clients and serialize them\n",
        "for name, client in clients.items():\n",
        "    client_data = load_model(f\"{COOP_TRAINING_NON_IID_PATH}/{name}_best_model.pth\")\n",
        "    client.model.load_state_dict(client_data[\"weights\"])\n",
        "save_clients(clients, COOP_TRAINING_NON_IID_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svtiOJfAtH2c"
      },
      "source": [
        "###Plot results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S7CXiIC2tH2d"
      },
      "outputs": [],
      "source": [
        "COOP_TRAINING_NON_IID_PATH = f\"{ROOT}/aml_project/results/fedmd/coop_training_non_iid\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K83cfwQgtH2d"
      },
      "outputs": [],
      "source": [
        "# Unpickle stats\n",
        "stats = pickle.load(open(f\"{COOP_TRAINING_NON_IID_PATH}/stats.p\", \"rb\"))\n",
        "acc_per_round = stats[\"acc\"]\n",
        "num_rounds = max([len(r) for r in acc_per_round])\n",
        "\n",
        "# Load upper and lower baselines data\n",
        "client_names = list(clients.keys())\n",
        "up_bl_acc = []\n",
        "low_bl_acc = []\n",
        "for name in client_names:\n",
        "    up_bl_acc.append(load_model(f\"{UPPER_BL_PATH}/{name}_best_model.pth\")[\"accuracy\"])\n",
        "    low_bl_acc.append(load_model(f\"{NON_IID_LOWER_BL_PATH}/{name}_best_model.pth\")[\"accuracy\"])\n",
        "\n",
        "\n",
        "# Plot baselines accuracies and accuracy across rounds\n",
        "plt.figure()\n",
        "x = [_ for _ in range(num_rounds)]\n",
        "low_bl_x = [_ for _ in range(int(num_rounds/3))]\n",
        "up_bl_x = [_ for _ in range(int(2*num_rounds/3))]\n",
        "for i in range(len(client_names)):\n",
        "    low_bl_y = [100*low_bl_acc[i] for _ in range(len(low_bl_x))]\n",
        "    plt.plot(low_bl_x, low_bl_y, \"--\", label=client_names[i])\n",
        "\n",
        "    up_bl_y = [100*up_bl_acc[i] for _ in range(len(up_bl_x))]\n",
        "    plt.plot(low_bl_x, low_bl_y, \"-.\", label=client_names[i])\n",
        "\n",
        "    y = [100*a for a in acc_per_round[i]]\n",
        "    plt.plot(x, y, \"-o\", label=client_names[i])\n",
        "\n",
        "plt.xlabel(\"Round\")\n",
        "plt.ylabel(\"Test Accuracy [%]\")\n",
        "plt.title(\"Accuracy per Round: Non-IID\")\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.savefig(f\"{COOP_TRAINING_NON_IID_PATH}/results\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}